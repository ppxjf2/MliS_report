\section{Conclusions}

The ML alorithm sucessfully demonstrated logarithmic improvement over time.
The cumulative reward function was a successful indicator for the performance of the drone to the high correlation.
The model shows signs of outperforming the Heuristic model but more simulations are required to demonstrate this with statistical significance.
This was a limited of the time contraint of the project.

For future improvements to this work, more simulations are recommended and over more epochs to improve the model.
Through collecting data for different actions and state spaces, it may be possible to improve the performance of the model.
