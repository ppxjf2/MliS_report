\section{Conclusions}

The ML algorithm successfully demonstrated logarithmic improvement over time, and therefore our actions and state space were appropriate for achieving some level of training.
Also, the cumulative reward function was a successful indicator for the performance of the drone to the high correlation.
The model shows signs of outperforming the Heuristic model but more simulations are required to demonstrate this with statistical significance. This was a limit of the time constraint of the project.


For future improvements to this work, more simulations are recommended and over more epochs to improve the model.
Through collecting data for different actions and state spaces, it may be possible to improve the performance of the model.
